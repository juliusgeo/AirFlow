{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Vx1', 'Vy1', 'Vz1', 'P1', 'P2', 'P3', 'P4', 'flowrate'], dtype='object')\n",
      "      Unnamed: 0       Vx1       Vy1           Vz1         P1         P2  \\\n",
      "0              0  3.876814  1.916041  1.006332e+00   6.136800  10.334200   \n",
      "1              1  3.102293  2.363314  3.961407e-01   7.893600   9.844900   \n",
      "2              2  3.041615  1.842067  4.934259e-01   8.116300   9.649200   \n",
      "3              3  5.166797  1.942071 -6.679608e-01   7.852400   8.572700   \n",
      "4              4  5.578229  2.074525 -6.780873e-01   6.796600   6.468700   \n",
      "5              5  6.344273  2.877890 -5.727502e-01   5.740800   5.049700   \n",
      "6              6  5.967801  2.607268 -7.880977e-01   4.775800   4.853900   \n",
      "7              7  5.738748  2.700450 -7.787451e-01   4.330400   3.777500   \n",
      "8              8  7.012391  1.337685 -1.374724e+00   4.487133   3.679600   \n",
      "9              9  5.478196  2.416172  1.777008e-01   4.643867   3.532800   \n",
      "10            10  5.259750  3.160377  6.449406e-01   4.800600   3.679600   \n",
      "11            11  5.057764  3.015032 -1.439055e-01   5.509900   4.266800   \n",
      "12            12  4.650083  3.112959 -2.149717e-01   5.889300   3.483900   \n",
      "13            13  4.940947  3.075469  3.047331e-02   7.299700   5.147500   \n",
      "14            14  4.375528  3.237721  4.283867e-01   9.172000   8.866300   \n",
      "15            15  5.610882  3.398071 -6.869490e-02   9.477100   8.915200   \n",
      "16            16  5.300132  2.986471  4.467530e-01   8.363700   8.670500   \n",
      "17            17  5.505171  0.346356  1.623463e+00   7.489500   6.713300   \n",
      "18            18  5.233953  1.490931  8.619539e-01   6.384200   8.083400   \n",
      "19            19  4.332755  1.910973  8.435140e-01   3.464400   3.092400   \n",
      "20            20  4.709468  2.931386  1.743297e-01   3.431400   6.958000   \n",
      "21            21  4.515031  2.843267  2.143038e-01   3.398400   3.679600   \n",
      "22            22  3.603254  3.044986  5.541860e-01   3.365400   4.266800   \n",
      "23            23  3.348129  3.666669  3.820608e-01   4.685100   2.407400   \n",
      "24            24  2.623548  2.823274  3.507481e-01   5.147000   4.364600   \n",
      "25            25  2.532205  1.426824 -1.421528e-01   5.641900   2.945600   \n",
      "26            26  3.335673  2.459270  5.455995e-01   8.537000   5.343200   \n",
      "27            27  3.860808  2.909328  4.995717e-01   9.897800   6.713300   \n",
      "28            28  2.939227  3.655661  2.951154e-01  10.854600   8.964100   \n",
      "29            29  3.102031  3.913789  2.442488e-01  11.630000   9.747000   \n",
      "...          ...       ...       ...           ...        ...        ...   \n",
      "8709        8709  6.345403  4.833902 -2.228147e-01 -13.190296   8.194877   \n",
      "8710        8710  4.050283  4.078659  6.955923e-01 -12.820470   4.028065   \n",
      "8711        8711  5.813575  2.987772  7.562865e-01 -12.450644   8.201675   \n",
      "8712        8712  6.412717  2.384868  3.346209e-01 -12.080818  20.430382   \n",
      "8713        8713  7.595021  4.473809  9.887294e-01 -11.710992  28.814877   \n",
      "8714        8714  7.559540  4.524292  1.537634e-02 -11.341166  31.484479   \n",
      "8715        8715  7.696023  4.997856 -6.577765e-01 -10.971340  30.760700   \n",
      "8716        8716  7.095273  5.136121  1.223087e-01 -12.081840  32.695804   \n",
      "8717        8717  7.260128  3.811653 -4.293490e-02 -10.630882  27.559594   \n",
      "8718        8718  6.001642  4.155734  1.274090e-02  -7.540527  25.088219   \n",
      "8719        8719  5.284250  5.120795 -1.541362e-01  -4.252363  21.216689   \n",
      "8720        8720  4.715967  6.036162 -2.084701e-10  -0.964200  19.542696   \n",
      "8721        8721  4.860938  5.455797 -2.041072e-01   1.857883   9.776975   \n",
      "8722        8722  7.144230  4.074997  8.644504e-01   2.539923   3.034234   \n",
      "8723        8723  7.786857  5.636744 -3.692907e-01   2.596109   0.199245   \n",
      "8724        8724  7.990461  5.532858  1.357124e-01   1.483805  -4.055131   \n",
      "8725        8725  7.740050  6.517727  1.589581e-01   0.371500   1.171166   \n",
      "8726        8726  7.830422  5.922102  2.284645e+00   9.186344   1.240845   \n",
      "8727        8727  8.405198  6.519740  1.684799e+00  18.543040   5.784331   \n",
      "8728        8728  8.915898  6.621530  5.625935e-01  23.524686   9.489068   \n",
      "8729        8729  8.448577  7.396170 -1.763932e-01  21.177393  14.418332   \n",
      "8730        8730  8.427001  5.878757 -3.229026e-01  18.830100  13.277807   \n",
      "8731        8731  8.105295  6.019523  2.820086e-01  19.306871  12.137282   \n",
      "8732        8732  7.937939  6.949140 -4.606207e-01  22.731001  10.996757   \n",
      "8733        8733  8.791807  8.460545 -1.088955e+00  19.539334   9.856232   \n",
      "8734        8734  9.256607  8.247336 -2.380483e-01   7.099667   8.715708   \n",
      "8735        8735  9.389061  9.035295 -5.005770e-01  -5.340000   7.575183   \n",
      "8736        8736  9.747402  7.479445 -3.002715e-01   2.725260   6.434658   \n",
      "8737        8737  9.860965  6.576446 -4.139080e-01   8.458458   5.294133   \n",
      "8738        8738  9.959707  6.870742 -8.447325e-02  14.556136   4.153609   \n",
      "\n",
      "             P3         P4  \n",
      "0      8.212600  -2.100800  \n",
      "1      9.180800  -0.050000  \n",
      "2      9.714800   2.501200  \n",
      "3     10.040400   1.200600  \n",
      "4      9.614800   1.388200  \n",
      "5      9.189200   1.575800  \n",
      "6      8.863600   0.875400  \n",
      "7      8.237700  -0.333500  \n",
      "8      8.062433  -1.097667  \n",
      "9      7.887167  -1.861833  \n",
      "10     7.711900  -2.626000  \n",
      "11     7.077600  -2.125800  \n",
      "12     7.511700  -0.375100  \n",
      "13     9.214200   0.400200  \n",
      "14    13.487500   2.651300  \n",
      "15    13.295600   1.350700  \n",
      "16    11.267500  -0.300100  \n",
      "17    13.095300   0.575300  \n",
      "18    13.654500   0.975500  \n",
      "19    11.242400  -2.000800  \n",
      "20    10.858467  -1.492267  \n",
      "21    10.474533  -0.983733  \n",
      "22    10.090600  -0.475200  \n",
      "23    10.791700  -1.900700  \n",
      "24    10.082400  -2.851100  \n",
      "25    10.941900  -2.567700  \n",
      "26    12.669700  -2.776100  \n",
      "27    14.572600  -2.526000  \n",
      "28    16.091400   3.368300  \n",
      "29    18.253400   7.778700  \n",
      "...         ...        ...  \n",
      "8709  -7.408904 -38.046194  \n",
      "8710  -5.981230 -38.614417  \n",
      "8711  -4.553556 -39.182641  \n",
      "8712  -3.125882 -39.750864  \n",
      "8713  -1.698208 -40.319088  \n",
      "8714  -0.270534 -40.887311  \n",
      "8715   1.157140 -41.455534  \n",
      "8716   6.488109 -40.398694  \n",
      "8717  12.524719 -39.071041  \n",
      "8718  15.717001 -36.063259  \n",
      "8719  23.884200 -35.367430  \n",
      "8720  32.051400 -34.671600  \n",
      "8721  31.773223 -27.035610  \n",
      "8722  29.478940 -25.265970  \n",
      "8723  27.884180 -24.022808  \n",
      "8724  26.361690 -23.742854  \n",
      "8725  24.839200 -23.462900  \n",
      "8726  25.048054 -27.098577  \n",
      "8727  36.651880 -23.380829  \n",
      "8728  39.590068 -21.260657  \n",
      "8729  41.530034 -17.700479  \n",
      "8730  43.470000 -14.140300  \n",
      "8731  39.609375 -16.033737  \n",
      "8732  44.228971 -18.391687  \n",
      "8733  45.520653 -23.730287  \n",
      "8734  40.125876 -25.890144  \n",
      "8735  34.731100 -28.050000  \n",
      "8736  41.787194 -29.162031  \n",
      "8737  45.298707 -34.833786  \n",
      "8738  47.502766 -34.319262  \n",
      "\n",
      "[35368 rows x 8 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35368"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "data = pd.concat([pd.read_csv(f) for f in glob.glob('se*.csv')])\n",
    "print(data.columns)\n",
    "data.dropna(inplace=True)\n",
    "target = data.pop('flowrate')\n",
    "m = np.median(target)\n",
    "v = np.var(target)**(.5)\n",
    "#target = target-np.min(target)\n",
    "#target = (target/v)\n",
    "#target = target*(100/np.max(target))\n",
    "print(data)\n",
    "data.pop('Unnamed: 0')\n",
    "batch_size = 256\n",
    "training_set_size = int(.2*len(data))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data.values, target.values)).shuffle(len(data)).batch(batch_size, drop_remainder=True).repeat(5)\n",
    "testset = dataset.take(training_set_size//batch_size)\n",
    "trainset = dataset.skip(training_set_size//batch_size)\n",
    "np.any(np.isnan(target))\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Use of this metric is not recommended; for illustration only. \n",
    "    See other regression metrics on sklearn docs:\n",
    "      http://scikit-learn.org/stable/modules/classes.html#regression-metrics\n",
    "    Use like any other metric\n",
    "    >>> y_true = [3, -0.5, 2, 7]; y_pred = [2.5, -0.3, 2, 8]\n",
    "    >>> mean_absolute_percentage_error(y_true, y_pred)\n",
    "    Out[]: 24.791666666666668\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    (\"linear_svc\", SVR(kernel='rbf', gamma='scale', coef0=.01, C=200))\n",
    "])\n",
    "a_train, a_test, b_train, b_test = train_test_split(data, target, test_size=0.2)\n",
    "svm_clf.fit(a_train, b_train)\n",
    "print(time.time()-start_time)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_percentage_error(b_test, svm_clf.predict(a_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_layer_size = 28\n",
    "model = Sequential([\n",
    "Dense(middle_layer_size, input_shape=(7,)),\n",
    "PReLU(),\n",
    "Dense(middle_layer_size),\n",
    "PReLU(),\n",
    "Dense(middle_layer_size),\n",
    "PReLU(),\n",
    "Dense(middle_layer_size),\n",
    "PReLU(),\n",
    "Dense(middle_layer_size),\n",
    "Dense(1)])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(.0001),\n",
    "            loss='mse',\n",
    "            metrics=['mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 663 steps, validate for 27 steps\n",
      "Epoch 1/200\n",
      "663/663 [==============================] - 2s 3ms/step - loss: 2250376.7900 - mape: 96.5933 - val_loss: 2042389.6019 - val_mape: 91.9916\n",
      "Epoch 2/200\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 1583831.5055 - mape: 80.0791 - val_loss: 1039773.9699 - val_mape: 64.0387\n",
      "Epoch 3/200\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 591858.6377 - mape: 45.0083 - val_loss: 343366.3403 - val_mape: 30.7876\n",
      "Epoch 4/200\n",
      "663/663 [==============================] - 2s 2ms/step - loss: 293440.2002 - mape: 27.0933 - val_loss: 277679.6510 - val_mape: 25.6799\n",
      "Epoch 5/200\n",
      "663/663 [==============================] - 2s 2ms/step - loss: 237813.4978 - mape: 23.8740 - val_loss: 222952.3258 - val_mape: 23.1176\n",
      "Epoch 6/200\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 207546.9912 - mape: 22.4756 - val_loss: 199804.4693 - val_mape: 22.1607\n",
      "Epoch 7/200\n",
      "  0/663 [..............................] - ETA: 0s - loss: 220090.3550 - mape: 22.4756 - val_loss: 199804.4693 - val_mape: 22.1607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-69a59207e9d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Visualize training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mtraining_data_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initializer\u001b[0m  \u001b[0;31m# pylint: disable=pointless-statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mtraining_data_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             training_result = run_one_epoch(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m     if (context.executing_eagerly()\n\u001b[1;32m    417\u001b[0m         or ops.get_default_graph()._building_function):  # pylint: disable=protected-access\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    592\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         dataset = _OptimizeDataset(dataset, static_optimizations,\n\u001b[0;32m--> 381\u001b[0;31m                                    static_optimization_configs)\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mautotune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[1;32m   4211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m         \u001b[0moptimization_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   4214\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_OptimizeDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[0;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   3625\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimization_configs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3627\u001b[0;31m         optimization_configs)\n\u001b[0m\u001b[1;32m   3628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(trainset, validation_data=testset,epochs=200)\n",
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "%matplotlib notebook\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['mape'])\n",
    "plt.plot(history.history['val_mape'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for pred, true in zip(model.predict(data), target):\n",
    "    print(pred[0]-true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for f in [f for f in glob.glob('*.csv')]:\n",
    "    print(f)\n",
    "    data = pd.read_csv(f)\n",
    "    data.dropna(inplace=True)\n",
    "    data.pop('Unnamed: 0')\n",
    "    target = data.pop('flowrate')\n",
    "    batch_size = 128\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data.values, target.values)).shuffle(len(data)).batch(batch_size, drop_remainder=True)\n",
    "    model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.5454476 ,  1.36063   ,  1.5803715 , -1.4860361 ,  1.3099797 ,\n",
      "         1.3650161 ,  0.93839836],\n",
      "       [-0.9372401 ,  0.73699605,  1.8344716 , -1.8222601 ,  0.89562494,\n",
      "         0.6452889 ,  0.6267038 ],\n",
      "       [-1.9186938 ,  0.6052026 ,  1.4968928 , -1.1818728 ,  1.2313176 ,\n",
      "         1.5121548 ,  0.54756784],\n",
      "       [-0.15362215, -0.3137385 ,  0.7023042 , -0.08800523,  0.28192505,\n",
      "         0.692691  ,  0.5755827 ],\n",
      "       [-0.2765888 , -0.06322658, -0.12207282, -0.32093886, -0.15663078,\n",
      "        -0.0716961 ,  0.2984124 ],\n",
      "       [-0.6291027 ,  0.38428885, -0.03159673, -0.9634274 ,  0.7092177 ,\n",
      "         0.31466174, -0.10971808],\n",
      "       [ 0.38720393,  0.52967376, -0.14171004,  0.13321222,  0.22842214,\n",
      "         0.30289927,  0.69630677]], dtype=float32), array([-1.8947358,  1.9121218,  1.9307961, -1.925397 ,  1.8710008,\n",
      "        1.7408864,  1.6571323], dtype=float32)]\n",
      "[array([ 0.5979945 , -0.7792143 , -0.07825326,  0.576131  ,  0.14097206,\n",
      "       -0.646331  , -1.1549027 ], dtype=float32)]\n",
      "[array([[-0.26330292, -1.0016903 , -1.0237168 , -0.8651001 , -1.0800956 ,\n",
      "        -0.85592914,  0.2160727 , -0.86280847,  0.5143989 ,  0.92140347,\n",
      "        -0.56521654,  0.9651142 , -0.9439537 , -1.0914614 ],\n",
      "       [ 1.2212856 ,  0.30700332,  1.2675207 ,  0.7785651 ,  0.909823  ,\n",
      "         1.0006928 , -1.0716592 ,  0.40753555, -0.9978068 , -0.4550016 ,\n",
      "         0.8257262 , -0.79639965,  0.27640307,  0.783229  ],\n",
      "       [ 0.48144495,  1.0561528 ,  0.6014909 ,  1.4071139 ,  1.4664366 ,\n",
      "         1.1497806 , -0.5388215 ,  0.52618986, -0.7881828 , -1.2079217 ,\n",
      "         0.90987086, -0.62008417,  1.3887337 ,  1.3069534 ],\n",
      "       [-0.80654174, -0.93845373, -0.93453085, -0.16047126, -0.7411818 ,\n",
      "        -0.45369497,  0.230926  , -0.3614407 ,  0.206196  ,  0.9959236 ,\n",
      "        -1.1435677 ,  0.1812251 , -1.0816711 , -0.9099908 ],\n",
      "       [ 0.6691273 ,  1.129694  ,  0.7398704 ,  0.5618295 ,  1.1941063 ,\n",
      "         0.3462512 , -0.6841128 ,  0.43812075, -1.1426789 , -0.91557527,\n",
      "         0.29958168, -0.9558251 ,  0.3381742 ,  1.1773661 ],\n",
      "       [ 0.10340139,  0.5012839 ,  1.0799215 ,  0.997011  ,  0.8322052 ,\n",
      "         0.7324709 , -0.6595531 ,  0.71457946, -1.0684658 , -0.9207168 ,\n",
      "         0.9652911 , -1.0402198 ,  0.55498505,  1.0188986 ],\n",
      "       [ 0.5907378 , -0.24868467,  0.51907045, -0.17012364,  0.32767203,\n",
      "        -0.20495433, -0.42527878,  0.4047395 , -0.15084204, -0.3875328 ,\n",
      "         0.23723346,  0.27506754,  0.52965343,  0.35244274]],\n",
      "      dtype=float32), array([ 1.6068169,  1.6378496,  1.5991347,  1.6028006,  1.5950106,\n",
      "        1.6603296, -1.6864772,  1.6304065, -1.6602824, -1.7045727,\n",
      "        1.6734226, -1.5996411,  1.5956388,  1.635595 ], dtype=float32)]\n",
      "[array([[ 0.8855553 ],\n",
      "       [ 1.0122881 ],\n",
      "       [ 1.0140705 ],\n",
      "       [ 1.4014007 ],\n",
      "       [ 1.2527281 ],\n",
      "       [ 1.0226393 ],\n",
      "       [-0.7761788 ],\n",
      "       [ 0.8975735 ],\n",
      "       [-0.65834504],\n",
      "       [-0.7493662 ],\n",
      "       [ 0.7963845 ],\n",
      "       [-1.4294449 ],\n",
      "       [ 1.1812675 ],\n",
      "       [ 0.9342441 ]], dtype=float32), array([1.507968], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    w = layer.get_weights()\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
